{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The below code represents the training of our NN on the track LR, make sure that you have the folder recodrings/LR/ in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880 training samples.\n",
      "97 validation samples.\n",
      "in new model\n",
      "\n",
      "Train on 880 samples, validate on 97 samples\n",
      "Epoch 1/100\n",
      "850/880 [===========================>..] - ETA: 0s - loss: nanEpoch 00001: val_loss did not improve\n",
      "880/880 [==============================] - 23s 26ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "450/880 [==============>...............] - ETA: 7s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e5162bb19b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mearlystopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     model.fit([X_train, z_train], y_train, batch_size=batch_size, epochs=epochs,\n\u001b[0;32m--> 227\u001b[0;31m               shuffle=True, validation_data=([X_val, z_val], y_val), callbacks=[checkpointer, earlystopping])\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import hashlib\n",
    "import time\n",
    "import argparse\n",
    "from mkdir_p import mkdir_p\n",
    "\n",
    "from PIL import Image, ImageMath, ImageChops\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Merge, Input, Reshape\n",
    "from keras.layers import Conv2D, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "TRACK_CODES = set(map(lambda s: s.lower(),\n",
    "    [\"ALL\", \"MR\",\"CM\",\"BC\",\"BB\",\"YV\",\"FS\",\"KTB\",\"RRy\",\"LR\",\"MMF\",\"TT\",\"KD\",\"SL\",\"RRd\",\"WS\",\n",
    "     \"BF\",\"SS\",\"DD\",\"DK\",\"BD\",\"TC\"]))\n",
    "\n",
    "def is_valid_track_code(value):\n",
    "    value = value.lower()\n",
    "    if value not in TRACK_CODES:\n",
    "        raise argparse.ArgumentTypeError(\"%s is an invalid track code\" % value)\n",
    "    return value\n",
    "\n",
    "OUT_SHAPE = 1\n",
    "\n",
    "INPUT_WIDTH = 200\n",
    "INPUT_HEIGHT = 66\n",
    "INPUT_CHANNELS = 3\n",
    "INPUT_CHANNELS_MAP = 3\n",
    "\n",
    "#for LR\n",
    "XMIN = 239\n",
    "XMAX = 300\n",
    "YMIN = 114\n",
    "YMAX = 220\n",
    "MAP_HEIGHT = 106\n",
    "MAP_WIDTH = 61\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "USE_REVERSE_IMAGES = False\n",
    "\n",
    "#Image.open('bla.png').convert('RGB')\n",
    "\n",
    "def customized_loss(y_true, y_pred, loss='euclidean'):\n",
    "    # Simply a mean squared error that penalizes large joystick summed values\n",
    "    if loss == 'L2':\n",
    "        L2_norm_cost = 0.001\n",
    "        val = K.mean(K.square((y_pred - y_true)), axis=-1) \\\n",
    "            + K.sum(K.square(y_pred), axis=-1) / 2 * L2_norm_cost\n",
    "    # euclidean distance loss\n",
    "    elif loss == 'euclidean':\n",
    "        val = K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
    "    return val\n",
    "\n",
    "def extract_map(frame, mask):\n",
    "    frameext = frame.crop((XMIN, YMIN, XMAX, YMAX))\n",
    "    trackMap = ImageChops.multiply(frameext, mask) #ImageMath.eval(\"a*b\", a=frameext, b = mask)\n",
    "    #trackMap.save(\"mapman.png\", \"PNG\")\n",
    "    trackMap_arr = np.frombuffer(trackMap.tobytes(), dtype=np.uint8)\n",
    "    trackMap_arr = trackMap_arr.reshape((MAP_HEIGHT, MAP_WIDTH, INPUT_CHANNELS))\n",
    "    #trackMap.save(\"mapman.png\", \"PNG\")\n",
    "    #print(\"finished extracting\")\n",
    "    return trackMap_arr;\n",
    "\n",
    "def create_model(keep_prob=0.6):\n",
    "    print(\"in new model\\n\")\n",
    "    # CNN for MAP\n",
    "    input_map  = Input(shape=(MAP_HEIGHT, MAP_WIDTH, INPUT_CHANNELS_MAP))\n",
    "    branch_map = BatchNormalization()(input_map)\n",
    "    branch_map = Conv2D(24, kernel_size=(5, 5), strides=(2, 2), activation='relu')(branch_map)\n",
    "    branch_map = BatchNormalization()(branch_map)\n",
    "    branch_map = Conv2D(36, kernel_size=(5, 5), strides=(2, 2), activation='relu')(branch_map)\n",
    "    branch_map = BatchNormalization()(branch_map)\n",
    "    branch_map = Conv2D(48, kernel_size=(5, 5), strides=(2, 2), activation='relu')(branch_map)\n",
    "    branch_map = BatchNormalization()(branch_map)\n",
    "    branch_map = Conv2D(64, kernel_size=(3, 3), activation='relu')(branch_map)\n",
    "    branch_map = BatchNormalization()(branch_map)\n",
    "    branch_map = Conv2D(64, kernel_size=(3, 3), activation='relu')(branch_map)\n",
    "    branch_map = Flatten()(branch_map)\n",
    "    \n",
    "    # CNN for frame\n",
    "    input_Frame  = Input(shape=(INPUT_HEIGHT, INPUT_WIDTH, INPUT_CHANNELS))\n",
    "    branch_frame = BatchNormalization()(input_Frame)\n",
    "    branch_frame = Conv2D(24, kernel_size=(5, 5), strides=(2, 2), activation='relu')(branch_frame)\n",
    "    branch_frame = BatchNormalization()(branch_frame)\n",
    "    branch_frame = Conv2D(36, kernel_size=(5, 5), strides=(2, 2), activation='relu')(branch_frame)\n",
    "    branch_frame = BatchNormalization()(branch_frame)\n",
    "    branch_frame = Conv2D(48, kernel_size=(5, 5), strides=(2, 2), activation='relu')(branch_frame)\n",
    "    branch_frame = BatchNormalization()(branch_frame)\n",
    "    branch_frame = Conv2D(64, kernel_size=(3, 3), activation='relu')(branch_frame)\n",
    "    branch_frame = BatchNormalization()(branch_frame)\n",
    "    branch_frame = Conv2D(64, kernel_size=(3, 3), activation='relu')(branch_frame)\n",
    "    branch_frame = Flatten()(branch_frame)\n",
    "    #branch_frame = LSTM(64, activation='relu')(branch_frame)\n",
    "    \n",
    "    # Merge CNN outputs     \n",
    "    concatenated_branches = concatenate([branch_frame, branch_map])\n",
    "    concatenated_branches = Dense(1164, activation='relu')(concatenated_branches)\n",
    "    drop_out = 1 - keep_prob\n",
    "    concatenated_branches = Dropout(drop_out)(concatenated_branches)\n",
    "    concatenated_branches = Dense(100, activation='relu')(concatenated_branches)\n",
    "    concatenated_branches = Dropout(drop_out)(concatenated_branches)\n",
    "    concatenated_branches = Dense( 50, activation='relu')(concatenated_branches)\n",
    "    concatenated_branches = Dropout(drop_out)(concatenated_branches)\n",
    "    concatenated_branches = Dense( 10, activation='relu')(concatenated_branches)\n",
    "    concatenated_branches = Dropout(drop_out)(concatenated_branches)\n",
    "    prediction = Dense(OUT_SHAPE, activation='softsign', name=\"predictions\")(concatenated_branches)\n",
    "    \n",
    "    model = Model(inputs=[input_Frame, input_map], outputs=prediction)\n",
    "\n",
    "    return model\n",
    "\n",
    "def is_validation_set(string):\n",
    "    string_hash = hashlib.md5(string.encode('utf-8')).digest()\n",
    "    return int.from_bytes(string_hash[:2], byteorder='big') / 2**16 > VALIDATION_SPLIT\n",
    "\n",
    "def load_training_data(track):\n",
    "    X_train, y_train, z_train = [], [], []\n",
    "    X_val, y_val, z_val = [], [], []\n",
    "\n",
    "    if track == 'all':\n",
    "        recordings = glob.iglob(\"recordings/*/*/*\")\n",
    "    else:\n",
    "        recordings = glob.iglob(\"recordings/{}/*/*\".format(track))\n",
    "\n",
    "    map_raw = Image.open(\"masks/mm_LR.png\").convert(\"RGB\") #Change LR to arg\n",
    "\n",
    "    for recording in recordings:\n",
    "        filenames = list(glob.iglob('{}/*.png'.format(recording)))\n",
    "        filenames.sort(key=lambda f: int(os.path.basename(f)[:-4]))\n",
    "\n",
    "        steering = [float(line) for line in open(\n",
    "            (\"{}/steering.txt\").format(recording)).read().splitlines()]\n",
    "\n",
    "        assert len(filenames) == len(steering), \"For recording %s, the number of steering values does not match the number of images.\" % recording\n",
    "\n",
    "        for file, steer in zip(filenames, steering):\n",
    "            assert steer >= -1 and steer <= 1\n",
    "\n",
    "            valid = is_validation_set(file)\n",
    "            valid_reversed = is_validation_set(file + '_flipped')\n",
    "\n",
    "            im = Image.open(file).resize((INPUT_WIDTH, INPUT_HEIGHT))\n",
    "            im_arr = np.frombuffer(im.tobytes(), dtype=np.uint8)\n",
    "            im_arr = im_arr.reshape((INPUT_HEIGHT, INPUT_WIDTH, INPUT_CHANNELS))\n",
    "\n",
    "            map_arr = extract_map(Image.open(file), map_raw)\n",
    "\n",
    "            if valid:\n",
    "                X_train.append(im_arr)\n",
    "                y_train.append(steer)\n",
    "                z_train.append(map_arr)\n",
    "            else:\n",
    "                X_val.append(im_arr)\n",
    "                y_val.append(steer)\n",
    "                z_val.append(map_arr)\n",
    "\n",
    "            if USE_REVERSE_IMAGES:\n",
    "                im_reverse = im.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                im_reverse_arr = np.frombuffer(im_reverse.tobytes(), dtype=np.uint8)\n",
    "                im_reverse_arr = im_reverse_arr.reshape((INPUT_HEIGHT, INPUT_WIDTH, INPUT_CHANNELS))\n",
    "\n",
    "                if valid_reversed:\n",
    "                    X_train.append(im_reverse_arr)\n",
    "                    y_train.append(-steer)\n",
    "                else:\n",
    "                    X_val.append(im_reverse_arr)\n",
    "                    y_val.append(-steer)\n",
    "\n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_val) == len(y_val)\n",
    "    assert len(z_train) == len(y_train)\n",
    "    assert len(z_val) == len(y_val)\n",
    "\n",
    "    return np.asarray(X_train), \\\n",
    "        np.asarray(y_train).reshape((len(y_train), 1)), \\\n",
    "        np.asarray(X_val), \\\n",
    "        np.asarray(y_val).reshape((len(y_val), 1)), \\\n",
    "        np.asarray(z_train), \\\n",
    "        np.asarray(z_val)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument('track', type=is_valid_track_code)\n",
    "    #parser.add_argument('-c', '--cpu', action='store_true', help='Force Tensorflow to use the CPU.', default=False)\n",
    "    #args = parser.parse_args()\n",
    "    \n",
    "    track = \"LR\"\n",
    "    \n",
    "    #if args.cpu:\n",
    "    #   os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    #  os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "    # Load Training Data\n",
    "    X_train, y_train, X_val, y_val, z_train, z_val = load_training_data(track)\n",
    "\n",
    "    print(X_train.shape[0], 'training samples.')\n",
    "    print(X_val.shape[0], 'validation samples.')\n",
    "\n",
    "    # Training loop variables\n",
    "    epochs = 100\n",
    "    batch_size = 50\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    mkdir_p(\"weights\")\n",
    "    weights_file = \"weights/{}.hdf5\".format(track)\n",
    "    #if os.path.isfile(weights_file):\n",
    "    #    model.load_weights(weights_file)\n",
    "\n",
    "    model.compile(loss=customized_loss, optimizer=optimizers.adam(lr=0.0001))\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        monitor='val_loss', filepath=weights_file, verbose=1, save_best_only=True, mode='min')\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    model.fit([X_train, z_train], y_train, batch_size=batch_size, epochs=epochs,\n",
    "              shuffle=True, validation_data=([X_val, z_val], y_val), callbacks=[checkpointer, earlystopping])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
